{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "lasting-childhood",
   "metadata": {},
   "source": [
    "# Imaging with Stride\n",
    "\n",
    "In this notebook, we will apply what we have seen previously to image a 2D section of the human breast using full-waveform inversion (FWI) in Stride.\n",
    "\n",
    "FWI is a tomographic imaging technique, originally developed in geophysics, that solves a local optimisation problem in order to find the acoustic properties (usually speed of sound) of some imaged region. \n",
    "\n",
    "Given some data that we have collected or observed $d_{obs}$ and some data that we have modelled numerically $d_{mod}$, FWI solves the problem,\n",
    "\n",
    "$$\n",
    "v_p^* = argmin_{v_p} J(v_p, d_{obs}, d_{mod})\n",
    "$$\n",
    "$$\n",
    "s.t.\\; \\mathbf{L}(d_{mod}, v_p) = \\mathbf{0}\n",
    "$$\n",
    "\n",
    "to find the speed of sound $v_p$, where $J(v_p, d_{obs}, d_{mod})$ is a scalar loss function and $\\mathbf{L}(d_{mod},v_p) = \\mathbf{0}$ is a system of PDEs.\n",
    "\n",
    "Most generally, we use the L2-norm of the distance between $d_{obs}$ and $d_{mod}$ as the loss function, and the acoustic wave equation as the PDE. The problem then becomes,\n",
    "\n",
    "$$\n",
    "v_p^* = argmin_{v_p} \\left\\langle \\frac{1}{2} \\left( p(v_p) \\delta(\\mathbf{x}-\\mathbf{x}_0) - d_{obs} \\right) ^2, 1 \\right\\rangle\n",
    "$$\n",
    "$$\n",
    "s.t.\\; \\frac{1}{v_p^2} \\frac{\\partial^2 p}{\\partial t^2} - \\nabla^2 p - s = 0\n",
    "$$\n",
    "\n",
    "where $\\left\\langle \\alpha, \\beta \\right\\rangle = \\int_{t_0}^{t_1}\\int_{\\Omega} \\alpha \\cdot \\beta d\\mathbf{x}^3dt$ for $t \\in [t_0, t_1]$ and $\\mathbf{x} \\in \\Omega$, $\\delta(x)$ is the sampling Dirac delta, $\\mathbf{x}_0$ is the location of receivers in the region, $p$ is the pressure, and $s$ is a source term.\n",
    "\n",
    "In FWI, we solve this problem by using a local optimisation method like gradient descent, and we calculate the gradient of the problem using the adjoint method or, what is the same, the procedure that we introduced in the first notebook of this tutorial.\n",
    "\n",
    "## Mosaic runtime\n",
    "\n",
    "Before we proceed, let's start the Mosaic runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-signal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mosaic\n",
    "await mosaic.interactive('off')\n",
    "await mosaic.interactive('on', num_workers=2, log_level='info')\n",
    "runtime = mosaic.runtime()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "announced-cambridge",
   "metadata": {},
   "source": [
    "## Problem definition\n",
    "\n",
    "Let's start by defining out problem as usual, starting with the spatiotemporal grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-pilot",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stride import Space, Time, Grid\n",
    "%matplotlib widget\n",
    "\n",
    "space = Space(shape=(356, 385), extra=(50, 50), absorbing=(40, 40), spacing=0.5e-3)\n",
    "time = Time(start=0.0e-6, step=0.08e-6, num=2500)\n",
    "\n",
    "grid = Grid(space, time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-origin",
   "metadata": {},
   "source": [
    "We create the problem object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-ridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stride import Problem\n",
    "\n",
    "problem = Problem(name='breast2D', space=space, time=time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breathing-guarantee",
   "metadata": {},
   "source": [
    "And we start filling it up we our transducers and geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-elephant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transducers\n",
    "# the default option will create a single point transducer\n",
    "problem.transducers.default()\n",
    "\n",
    "# Create geometry\n",
    "# a default elliptical geometry will be generated in this case\n",
    "num_locations = 120\n",
    "problem.geometry.default('elliptical', num_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-daniel",
   "metadata": {},
   "source": [
    "We are going to populate our acquisition sequence with 120 shots (one for each location in the geoemtry). During each shot, a different location is going to act as the source and the rest of them are going to act as receivers.\n",
    "\n",
    "We can easily do this in Stride by calling the `default()` method of the `stride.Acquisitions` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-pressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stride.utils import wavelets\n",
    "\n",
    "# Populate acquisitions with default shots\n",
    "problem.acquisitions.default()\n",
    "\n",
    "# Create wavelets\n",
    "f_centre = 0.50e6\n",
    "n_cycles = 3\n",
    "\n",
    "for shot in problem.acquisitions.shots:\n",
    "    shot.wavelets.data[0, :] = wavelets.tone_burst(f_centre, n_cycles, time.num, time.step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legitimate-linux",
   "metadata": {},
   "source": [
    "Now, let's load our breast model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-tribe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stride import ScalarField\n",
    "\n",
    "# Create medium\n",
    "vp_true = ScalarField(name='vp', grid=grid)\n",
    "vp_true.load('../examples/breast2D/data/anastasio2D-TrueModel.h5')\n",
    "\n",
    "problem.medium.add(vp_true)\n",
    "problem.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e9cfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_lambda = 1500. / f_centre\n",
    "sigma = wave_lambda / 4\n",
    "for loc in problem.geometry.locations:\n",
    "    x , y = loc.coordinates \n",
    "    perturb_x = random.normal(0,sigma)\n",
    "    perturb_y = random.normal(0,sigma)\n",
    "    loc.coordinates  = np.array([x+perturb_x , y +perturb_y])\n",
    "problem.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-report",
   "metadata": {},
   "source": [
    "## Modelling operator\n",
    "\n",
    "Once we have generated our problem, we can create a PDE on which to run our forward problem. In this case, we choose the isotropic acoustic wave equation.\n",
    "\n",
    "We instantiate our PDE using `remote(len=<num>)` so that instances of the PDE are created in the workers for remote execution. We choose `len=runtime.num_workers` so that one instance is created in each available worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-tolerance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stride import IsoAcousticDevito\n",
    "\n",
    "pde = IsoAcousticDevito.remote(grid=problem.grid, len=runtime.num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sporting-platform",
   "metadata": {},
   "source": [
    "## Forward problem - Generating observed data\n",
    "\n",
    "Before we can proceed with the imaging bit, we need to simulate the acquisition of some observed data.\n",
    "\n",
    "Here, we will exploit the parallelisation capabilities of Mosaic to run different shots in parallel in each available worker. We do this with an asynchronous for loop using `@runtime.async_for(<iterable>)`. In the previous code section, the async function `loop()` is called as many times as there are shots in the acquisitions and, for each shot, it is assigned a worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-springfield",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all remaining shot IDs\n",
    "shot_ids = problem.acquisitions.remaining_shot_ids\n",
    "\n",
    "# Run an asynchronous loop across all shot IDs\n",
    "@runtime.async_for(shot_ids)\n",
    "async def loop(worker, shot_id):\n",
    "    runtime.logger.info('Giving shot %d to %s' % (shot_id, worker.uid))\n",
    "\n",
    "    # Fetch one sub-problem corresponding to a shot ID\n",
    "    sub_problem = problem.sub_problem(shot_id)\n",
    "    \n",
    "    # Access the source wavelets of this shot\n",
    "    wavelets = sub_problem.shot.wavelets\n",
    "    \n",
    "    # Execute the PDE forward\n",
    "    traces = await pde(wavelets, vp_true,\n",
    "                       problem=sub_problem,\n",
    "                       runtime=worker).result()\n",
    "\n",
    "    runtime.logger.info('Shot %d retrieved' % sub_problem.shot_id)\n",
    "\n",
    "    # Store the retrieved traces into the shot\n",
    "    shot = problem.acquisitions.get(shot_id)\n",
    "    shot.observed.data[:] = traces.data\n",
    "\n",
    "    runtime.logger.info('Retrieved traces for shot %d' % sub_problem.shot_id)\n",
    "\n",
    "# Because this is an asynchronous loop, it needs to be awaited \n",
    "_ = await loop\n",
    "\n",
    "# Plot the result\n",
    "_ = problem.acquisitions.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuing-portsmouth",
   "metadata": {},
   "source": [
    "Because the loop we just ran is a very common piece of code, we can obtain the same result by running the utility function `forward()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-ability",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stride import forward\n",
    "\n",
    "# Run default forward workflow\n",
    "# await forward(problem, pde, vp_true, dump=False)  # uncomment to run using utility function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b5ef0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.random as random\n",
    "wave_lambda = 1500. / f_centre\n",
    "sigma = wave_lambda / 4\n",
    "\n",
    "print(problem.geometry.locations[0].coordinates)\n",
    "\n",
    "for loc in problem.geometry.locations:\n",
    "    x , y = loc.coordinates \n",
    "    perturb_x = random.normal(0,sigma)\n",
    "    perturb_y = random.normal(0,sigma)\n",
    "    loc.coordinates  = np.array([x+perturb_x , y +perturb_y])\n",
    "    \n",
    "print(problem.geometry.locations[0].coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88eb3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "sub = problem.acquisitions.get(2)\n",
    "signal = sub.observed.data[2]\n",
    "# sub.observed.data[1] = np.random.rand(2500)\n",
    "\n",
    "noise = np.random.normal(0, 0.2, signal.shape)\n",
    "noisy_signal = signal + noise\n",
    "\n",
    "# Step 3: Visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(signal[:300], label='Original Signal')\n",
    "plt.title('Original Signal')\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(noise[:300], label='Noisy Signal')\n",
    "plt.title('Signal with Noise')\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Step 4: Compute Signal-to-Noise Ratio (SNR)\n",
    "SP = np.sqrt(np.mean(signal[:300] ** 2))\n",
    "NP = np.sqrt(np.mean(noise[:300] ** 2))\n",
    "SNR = 10 * np.log10(SP / NP)\n",
    "print(f'Signal-to-Noise Ratio (SNR): {SNR:.2f} dB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vietnamese-favor",
   "metadata": {},
   "source": [
    "## Starting model\n",
    "\n",
    "Before we can proceed with the imaging process, we need to determine a starting point for our inversion, a starting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-metadata",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "vp = ScalarField.parameter(name='vp', grid=grid, needs_grad=True)\n",
    "vp.fill(1500.)\n",
    "\n",
    "problem.medium.add(vp)\n",
    "\n",
    "wave_lambda = 1500. / f_centre\n",
    "perturb = wave_lambda / 40\n",
    "\n",
    "class Coords:\n",
    "    def __init__(self,coordinates):\n",
    "        self.coordinates =coordinates\n",
    "    \n",
    "    def load(self):\n",
    "        return self.coordinates\n",
    "    \n",
    "class Description:\n",
    "    def __init__(self):\n",
    "        self.locations = []\n",
    "\n",
    "    def add_item(self, id ,transducer_id,coordinates):\n",
    "        location_desc = LocationDescription(id, transducer_id, coordinates)\n",
    "        self.locations.append(location_desc)\n",
    "\n",
    "class LocationDescription:\n",
    "    def __init__(self, id, transducer_id, coordinates, orientation=None):\n",
    "        self.id = id\n",
    "        self.transducer_id = transducer_id\n",
    "        self.coordinates = Coords(coordinates)\n",
    "        self.orientation = orientation\n",
    "\n",
    "    def __iter__(self):\n",
    "    # Yielding attributes one by one\n",
    "        yield ('id', self.id)\n",
    "        yield ('transducer_id', self.transducer_id)\n",
    "        yield ('coordinates', self.coordinates)\n",
    "        if self.orientation is not None:\n",
    "            yield ('orientation', self.orientation)\n",
    "\n",
    "# sub_problem = problem.sub_problem(shot.id)\n",
    "descript= problem.geometry.__get_desc__()\n",
    "print(\"original desc:\", descript[\"locations\"])\n",
    "new_desc = Description()\n",
    "\n",
    "for loc in descript[\"locations\"]:\n",
    "    \n",
    "    original_x, original_y = loc[\"coordinates\"]\n",
    "    angle = random.uniform(0, 2 * math.pi)\n",
    "    new_x = original_x + perturb * math.cos(angle)\n",
    "    new_y = original_y + perturb * math.sin(angle)\n",
    "    loc[\"coordinates\"] = [new_x, new_y]\n",
    "\n",
    "    new_desc.add_item(loc[\"id\"], loc[\"transducer_id\"], np.array(loc[\"coordinates\"]))\n",
    "    # print(\"Updated coordinates:\", loc[\"coordinates\"])\n",
    "\n",
    "problem.geometry.__set_desc__(new_desc)\n",
    "descript= problem.geometry.__get_desc__()\n",
    "print(\"new desc:\", descript[\"locations\"])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drawn-vietnam",
   "metadata": {},
   "source": [
    "Unlike our forward example, the speed-of-sound field is unknown to us at this point. So, we define our starting guess for the speed of sound to be homogeneous with a value of 1500 m/s. Because we are going to run our inversion with respect to `vp`, we also define the field with `needs_grad=True`. That will instruct Stride to calculate the gradient of this variable when running the optimisation loop.\n",
    "\n",
    "You can also see that the field has now been instantiated using `parameter()`. This will turn `vp` into a remotely addressable object. What this means is that, as `vp` travels through our Mosaic network, it will always keep a reference to its original object here in our code. This will effectively allow us to accumulate the gradients calculated across different workers into a single local buffer.\n",
    "\n",
    "## Imaging operators\n",
    "\n",
    "Apart from our PDE operator, which we have already defined above, we will need to define an operator for our loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sophisticated-minute",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stride import L2DistanceLoss \n",
    "\n",
    "loss = L2DistanceLoss.remote(len=runtime.num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-making",
   "metadata": {},
   "source": [
    "We will also need some operators to proprocess the source wavelents and the modelled and observed data traces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-apple",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stride import ProcessWavelets, ProcessObserved, ProcessWaveletsObserved, ProcessTraces\n",
    "\n",
    "process_wavelets = ProcessWavelets.remote(len=runtime.num_workers)\n",
    "process_observed = ProcessObserved.remote(len=runtime.num_workers)\n",
    "process_wavelets_observed = ProcessWaveletsObserved.remote(len=runtime.num_workers)\n",
    "process_traces = ProcessTraces.remote(len=runtime.num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-translation",
   "metadata": {},
   "source": [
    "Finally, we will need an optimiser to update the speed of sound model after each iteration. In this case, we use gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-consideration",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stride import GradientDescent, ProcessGlobalGradient, ProcessModelIteration\n",
    "\n",
    "step_size = 10\n",
    "process_grad = ProcessGlobalGradient()\n",
    "process_model = ProcessModelIteration(min=1400., max=1700.)\n",
    "\n",
    "optimiser = GradientDescent(vp, step_size=step_size,\n",
    "                            process_grad=process_grad,\n",
    "                            process_model=process_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understanding-theorem",
   "metadata": {},
   "source": [
    "You can see that we have also provided to the optimiser some pre-defined processing steps. These will be used to prepare the gradient before updating the variable, and to process the variable after the update. \n",
    "\n",
    "Among other things, these processing steps will normalise and smooth the gradient, and will clip the speed of sound of the updated model between 1400 m/s and 1700 m/s.\n",
    "\n",
    "## Inverse problem - Estimating speed of sound\n",
    "\n",
    "We can now proceed to solve the inverse problem, that is finding the speed of sound that explains the data that we have generated above.\n",
    "\n",
    "To obtain a better posed optimisation, we use a multi-scale approach. We will start our inversion by using only low frequencies to construct our model. As the inversion progresses, we will add higher frequencies until we reach the maximum desired level of detail.\n",
    "\n",
    "We can do this by dividing our optimisation in `Block`s and specifying a maximum frequency. Each `Block` will run for a number of specified iterations.\n",
    "\n",
    "During each iteration, only a subset of the shots will be used by defining the `select_shots` field. In this case, 15 shots will be used for each iteration, and they will be selected randomly without replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-dayton",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stride import OptimisationLoop\n",
    "\n",
    "# Clear the previous Devito operators\n",
    "await pde.clear_operators()\n",
    "\n",
    "optimisation_loop = OptimisationLoop()\n",
    "\n",
    "# Specify a series of frequency bands, which we will introduce gradually \n",
    "# into the inversion in order to better condition it\n",
    "max_freqs = [0.3e6, 0.4e6]\n",
    "\n",
    "num_blocks = len(max_freqs)\n",
    "num_iters = 4\n",
    "\n",
    "# Start iterating over each block in the optimisation\n",
    "for block, f_max in optimisation_loop.blocks(num_blocks, max_freqs):\n",
    "\n",
    "    # Proceed through every iteration in the block\n",
    "    for iteration in block.iterations(num_iters):\n",
    "        runtime.logger.info('Starting iteration %d (out of %d), '\n",
    "                            'block %d (out of %d)' %\n",
    "                            (iteration.id+1, block.num_iterations, block.id+1,\n",
    "                             optimisation_loop.num_blocks))\n",
    "\n",
    "        # Select some shots for this iteration\n",
    "        shot_ids = problem.acquisitions.select_shot_ids(num=15, randomly=True)\n",
    "\n",
    "        # Clear the gradient buffers of the variable\n",
    "        vp.clear_grad()\n",
    "\n",
    "        # Asynchronously loop over all the selected shot IDs\n",
    "        @runtime.async_for(shot_ids)\n",
    "        async def loop(worker, shot_id):\n",
    "            runtime.logger.info('Giving shot %d to %s' % (shot_id, worker.uid))\n",
    "\n",
    "            # Fetch one sub-problem corresponding to the shot ID\n",
    "            sub_problem = problem.sub_problem(shot_id)\n",
    "            wavelets = sub_problem.shot.wavelets\n",
    "            observed = sub_problem.shot.observed\n",
    "\n",
    "            # Pre-process the wavelets and observed\n",
    "            wavelets = process_wavelets(wavelets, f_max=f_max, filter_relaxation=0.75, runtime=worker)\n",
    "            observed = process_observed(observed, f_max=f_max, filter_relaxation=0.75, runtime=worker)\n",
    "            processed = process_wavelets_observed(wavelets, observed, f_max=f_max, runtime=worker)\n",
    "            wavelets = processed.outputs[0]\n",
    "            observed = processed.outputs[1]\n",
    "            \n",
    "            # Execute the PDE forward\n",
    "            modelled = pde(wavelets, vp, problem=sub_problem, runtime=worker)\n",
    "\n",
    "            # Pre-process the modelled and observed traces\n",
    "            traces = process_traces(modelled, observed, f_max=f_max, filter_relaxation=0.75, runtime=worker)\n",
    "            # and use these pre-processed versions to calculate the\n",
    "            # value of the loss_freq function\n",
    "            fun = await loss(traces.outputs[0], traces.outputs[1],\n",
    "                             problem=sub_problem, runtime=worker).result()\n",
    "\n",
    "            iteration.add_loss(fun)\n",
    "            runtime.logger.info('Functional value for shot %d: %s' % (shot_id, fun))\n",
    "\n",
    "            # Now, we can calculate the gradient by executing the adjoint of the\n",
    "            # forward process\n",
    "            await fun.adjoint()\n",
    "\n",
    "            runtime.logger.info('Retrieved gradient for shot %d' % sub_problem.shot_id)\n",
    "\n",
    "        # Because this is an async loop, it needs to be awaited    \n",
    "        _ = await loop\n",
    "        # Update the vp with the calculated gradient by taking a step with the optimiser\n",
    "        await optimiser.step()\n",
    "\n",
    "        runtime.logger.info('Done iteration %d (out of %d), '\n",
    "                            'block %d (out of %d) - Total loss_freq %e' %\n",
    "                            (iteration.id+1, block.num_iterations, block.id+1,\n",
    "                             optimisation_loop.num_blocks, iteration.total_loss))\n",
    "        runtime.logger.info('====================================================================')\n",
    "\n",
    "# Plot the vp afterwards   \n",
    "vp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-graphics",
   "metadata": {},
   "source": [
    "As was the case for the forward example, we can obtain the same result by using a utility function that will run the default inversion workflow using `adjoint`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0135257f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "wave_lambda = 1500. / f_centre\n",
    "perturb = wave_lambda / 4\n",
    "\n",
    "class Coords:\n",
    "    def __init__(self,coordinates):\n",
    "        self.coordinates =coordinates\n",
    "    \n",
    "    def load(self):\n",
    "        return self.coordinates\n",
    "    \n",
    "class Description:\n",
    "    def __init__(self):\n",
    "        self.locations = []\n",
    "\n",
    "    def add_item(self, id ,transducer_id,coordinates):\n",
    "        location_desc = LocationDescription(id, transducer_id, coordinates)\n",
    "        self.locations.append(location_desc)\n",
    "\n",
    "class LocationDescription:\n",
    "    def __init__(self, id, transducer_id, coordinates, orientation=None):\n",
    "        self.id = id\n",
    "        self.transducer_id = transducer_id\n",
    "        self.coordinates = Coords(coordinates)\n",
    "        self.orientation = orientation\n",
    "\n",
    "    def __iter__(self):\n",
    "    # Yielding attributes one by one\n",
    "        yield ('id', self.id)\n",
    "        yield ('transducer_id', self.transducer_id)\n",
    "        yield ('coordinates', self.coordinates)\n",
    "        if self.orientation is not None:\n",
    "            yield ('orientation', self.orientation)\n",
    "\n",
    "# sub_problem = problem.sub_problem(shot.id)\n",
    "descript= problem.geometry.__get_desc__()\n",
    "print(\"original desc:\", descript[\"locations\"])\n",
    "new_desc = Description()\n",
    "\n",
    "for loc in descript[\"locations\"]:\n",
    "    \n",
    "    original_x, original_y = loc[\"coordinates\"]\n",
    "    angle = random.uniform(0, 2 * math.pi)\n",
    "    new_x = original_x + perturb * math.cos(angle)\n",
    "    new_y = original_y + perturb * math.sin(angle)\n",
    "    loc[\"coordinates\"] = [new_x, new_y]\n",
    "\n",
    "    new_desc.add_item(loc[\"id\"], loc[\"transducer_id\"], np.array(loc[\"coordinates\"]))\n",
    "    # print(\"Updated coordinates:\", loc[\"coordinates\"])\n",
    "\n",
    "problem.geometry.__set_desc__(new_desc)\n",
    "descript= problem.geometry.__get_desc__()\n",
    "print(\"new desc:\", descript[\"locations\"])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adf9d6c",
   "metadata": {},
   "source": [
    "### run reverse again with shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6feb990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stride import OptimisationLoop\n",
    "vp2 = ScalarField.parameter(name='vp', grid=grid, needs_grad=True)\n",
    "vp2.fill(1500.)\n",
    "\n",
    "problem.medium.add(vp2)\n",
    "# Clear the previous Devito operators\n",
    "await pde.clear_operators()\n",
    "\n",
    "optimisation_loop = OptimisationLoop()\n",
    "\n",
    "# Specify a series of frequency bands, which we will introduce gradually \n",
    "# into the inversion in order to better condition it\n",
    "max_freqs = [0.3e6, 0.4e6]\n",
    "\n",
    "num_blocks = len(max_freqs)\n",
    "num_iters = 4\n",
    "\n",
    "# Start iterating over each block in the optimisation\n",
    "for block, f_max in optimisation_loop.blocks(num_blocks, max_freqs):\n",
    "\n",
    "    # Proceed through every iteration in the block\n",
    "    for iteration in block.iterations(num_iters):\n",
    "        runtime.logger.info('Starting iteration %d (out of %d), '\n",
    "                            'block %d (out of %d)' %\n",
    "                            (iteration.id+1, block.num_iterations, block.id+1,\n",
    "                             optimisation_loop.num_blocks))\n",
    "\n",
    "        # Select some shots for this iteration\n",
    "        shot_ids = problem.acquisitions.select_shot_ids(num=15, randomly=True)\n",
    "\n",
    "        # Clear the gradient buffers of the variable\n",
    "        vp2.clear_grad()\n",
    "\n",
    "        # Asynchronously loop over all the selected shot IDs\n",
    "        @runtime.async_for(shot_ids)\n",
    "        async def loop(worker, shot_id):\n",
    "            runtime.logger.info('Giving shot %d to %s' % (shot_id, worker.uid))\n",
    "\n",
    "            # Fetch one sub-problem corresponding to the shot ID\n",
    "            sub_problem = problem.sub_problem(shot_id)\n",
    "            wavelets = sub_problem.shot.wavelets\n",
    "            observed = sub_problem.shot.observed\n",
    "\n",
    "            # Pre-process the wavelets and observed\n",
    "            wavelets = process_wavelets(wavelets, f_max=f_max, filter_relaxation=0.75, runtime=worker)\n",
    "            observed = process_observed(observed, f_max=f_max, filter_relaxation=0.75, runtime=worker)\n",
    "            processed = process_wavelets_observed(wavelets, observed, f_max=f_max, runtime=worker)\n",
    "            wavelets = processed.outputs[0]\n",
    "            observed = processed.outputs[1]\n",
    "            \n",
    "            # Execute the PDE forward\n",
    "            modelled = pde(wavelets, vp2, problem=sub_problem, runtime=worker)\n",
    "\n",
    "            # Pre-process the modelled and observed traces\n",
    "            traces = process_traces(modelled, observed, f_max=f_max, filter_relaxation=0.75, runtime=worker)\n",
    "            # and use these pre-processed versions to calculate the\n",
    "            # value of the loss_freq function\n",
    "            fun = await loss(traces.outputs[0], traces.outputs[1],\n",
    "                             problem=sub_problem, runtime=worker).result()\n",
    "\n",
    "            iteration.add_loss(fun)\n",
    "            runtime.logger.info('Functional value for shot %d: %s' % (shot_id, fun))\n",
    "\n",
    "            # Now, we can calculate the gradient by executing the adjoint of the\n",
    "            # forward process\n",
    "            await fun.adjoint()\n",
    "\n",
    "            runtime.logger.info('Retrieved gradient for shot %d' % sub_problem.shot_id)\n",
    "\n",
    "        # Because this is an async loop, it needs to be awaited    \n",
    "        _ = await loop\n",
    "        # Update the vp with the calculated gradient by taking a step with the optimiser\n",
    "        await optimiser.step()\n",
    "\n",
    "        runtime.logger.info('Done iteration %d (out of %d), '\n",
    "                            'block %d (out of %d) - Total loss_freq %e' %\n",
    "                            (iteration.id+1, block.num_iterations, block.id+1,\n",
    "                             optimisation_loop.num_blocks, iteration.total_loss))\n",
    "        runtime.logger.info('====================================================================')\n",
    "\n",
    "# Plot the vp afterwards   \n",
    "vp2.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e15b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(problem.acquisitions.shot_ids)\n",
    "subproblem = problem.sub_problem(10)\n",
    "print(subproblem.shot.observed.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indoor-track",
   "metadata": {},
   "outputs": [],
   "source": [
    "await mosaic.interactive('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-authorization",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
